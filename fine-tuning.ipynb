{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHhmCKkNspko"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DiTo97/binarization-segformer/blob/main/fine-tuning.ipynb)\n",
        "\n",
        "# Fine-tuning Segformer for Document Image Binarization\n",
        "\n",
        "A notebook by F. Minutoli ([@DiTo97](https://github.com/DiTo97)) that fine-tunes a Segformer model for document image binarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "requirements = \" \".join([\n",
        "    \"absl-py==1.4.0\",\n",
        "    \"accelerate==0.18.0\",\n",
        "    \"albumentations==1.3.0\",\n",
        "    \"datasets==2.11.0\",\n",
        "    \"deepspeed==0.9.5\",\n",
        "    \"evaluate==0.4.0\",\n",
        "    \"huggingface-hub==0.13.4\",\n",
        "    \"tensorboardX==2.6.1\",\n",
        "    \"transformers==4.27.4\"\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM5vjXhqzxKg"
      },
      "outputs": [],
      "source": [
        "%%bash -s {requirements}\n",
        "set -e\n",
        "\n",
        "\n",
        "requirements=$@\n",
        "\n",
        "python -m pip install --upgrade pip\n",
        "python -m pip install $requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kc8nRW5-PXZp"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n97yPqpGPZS8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /home/fminutoli/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NfSYzsksymV"
      },
      "source": [
        "## 1. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1lJUa-B2YrFX"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "\n",
        "if [ ! -d SauvolaNet ]; then\n",
        "    git clone https://github.com/Leedeng/SauvolaNet.git\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A0yHI8-VxWAG"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import typing\n",
        "from typing import Any\n",
        "\n",
        "import datasets\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ieXXmK7b_M4v"
      },
      "outputs": [],
      "source": [
        "def normalize(bitmap: Image.Image) -> Image.Image:\n",
        "    bitmap = bitmap.convert(\"L\")\n",
        "    bitmap = np.array(bitmap).astype(np.uint8)\n",
        "    condition = bitmap < np.max(bitmap)\n",
        "    bitmap = np.where(condition, 1, 0).astype(np.bool_)\n",
        "    bitmap = Image.fromarray(bitmap)\n",
        "\n",
        "    return bitmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8J0xuvfh6xZ5"
      },
      "outputs": [],
      "source": [
        "def prepare_examples(\n",
        "    batch: typing.Dict[str, typing.List[Any]]\n",
        ") -> typing.Dict[str, typing.List[Any]]:\n",
        "    \"\"\"It prepares a batch of examples for semantic segmentation\"\"\"\n",
        "    sources = batch[\"source\"]\n",
        "    targets = batch[\"target\"]\n",
        "\n",
        "    batch = {\n",
        "        \"labelmap\": [normalize(Image.open(tgt)) for tgt in targets],\n",
        "        \"pixelmap\": [Image.open(src) for src in sources]\n",
        "    }\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dj2-dnCBvhVp"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0914239622e408391a22187d3b37a36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading datasets:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f42e4ec45b04fed9ba3efc1d58ad9ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/207 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a25563eb4d7c40f9bddbf6bfd27c8514",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting to class labels:   0%|          | 0/207 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sauvolanet_src = \"SauvolaNet/SauvolaDocBin\"\n",
        "sauvolanet_dataset = \"SauvolaNet/Dataset\"\n",
        "\n",
        "sys.path.insert(0, sauvolanet_src)\n",
        "from dataUtils import collect_binarization_by_dataset\n",
        "\n",
        "collection = collect_binarization_by_dataset(sauvolanet_dataset)\n",
        "\n",
        "sys.path.remove(sauvolanet_src)\n",
        "\n",
        "del sauvolanet_src\n",
        "del sauvolanet_dataset\n",
        "del collect_binarization_by_dataset\n",
        "\n",
        "features = datasets.Features({\n",
        "    \"ensemble\": datasets.Value(\"string\"),\n",
        "    \"source\": datasets.Value(\"string\"),\n",
        "    \"target\": datasets.Value(\"string\"),\n",
        "})\n",
        "\n",
        "for name, examples in tqdm(collection.items(), desc=\"Loading datasets\"):\n",
        "    sources, targets = zip(*examples)\n",
        "\n",
        "    sources = sorted(sources)\n",
        "    targets = sorted(targets)\n",
        "\n",
        "    dataset = {\"source\": sources, \"target\": targets, \"ensemble\": [name] * len(sources)}\n",
        "    dataset = datasets.Dataset.from_dict(dataset, features)\n",
        "\n",
        "    collection[name] = dataset\n",
        "\n",
        "collection = datasets.concatenate_datasets([\n",
        "    dataset for _, dataset in collection.items()\n",
        "])\n",
        "\n",
        "features = datasets.Features({\n",
        "    \"ensemble\": datasets.Value(\"string\"),\n",
        "    \"labelmap\": datasets.Image(),\n",
        "    \"pixelmap\": datasets.Image(),\n",
        "})\n",
        "\n",
        "collection = collection.map(\n",
        "    prepare_examples, \n",
        "    batched=True,\n",
        "    features=features, \n",
        "    remove_columns=[\"source\", \"target\"]\n",
        ")\n",
        "\n",
        "collection = collection.class_encode_column(\"ensemble\")\n",
        "\n",
        "del features\n",
        "\n",
        "collection = collection.train_test_split(\n",
        "    seed=10,\n",
        "    shuffle=True,\n",
        "    stratify_by_column=\"ensemble\",\n",
        "    train_size=0.75\n",
        ")\n",
        "\n",
        "train_dataset = collection[\"train\"]\n",
        "test_dataset  = collection[ \"test\"]\n",
        "\n",
        "del collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oTHsmOTaMsOM"
      },
      "outputs": [],
      "source": [
        "labels = [\"background\", \"text\"]\n",
        "num_labels = len(labels)\n",
        "\n",
        "id2label = {key: val for key, val in enumerate(labels)}\n",
        "label2id = {val: key for key, val in enumerate(labels)}\n",
        "\n",
        "del labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YsmKoUMNRtf"
      },
      "source": [
        "## 2. Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SnfP2XpoOHlE"
      },
      "outputs": [],
      "source": [
        "import albumentations\n",
        "import cv2 as opencv\n",
        "import transformers\n",
        "from transformers import set_seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9nVPfUEUOVvq"
      },
      "outputs": [],
      "source": [
        "set_seed(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FuGbJ6xz6n9E"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fminutoli/.conda/envs/binarization-segformer/lib/python3.7/site-packages/transformers/models/segformer/image_processing_segformer.py:102: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "base_model_name = \"nvidia/segformer-b3-finetuned-cityscapes-1024-1024\"\n",
        "base_model_size = {\"height\": 1024, \"width\": 1024}\n",
        "\n",
        "processor = transformers.SegformerImageProcessor.from_pretrained(base_model_name)\n",
        "processor.size.update(base_model_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xBhurCGKF5Rs"
      },
      "outputs": [],
      "source": [
        "FLAGS = {\n",
        "    # The general kwargs\n",
        "    \"border_mode\": opencv.BORDER_CONSTANT,\n",
        "    \"fill_value\": 255,\n",
        "    \"mask_fill_value\": 0,\n",
        "    \"proba\": 0.1,\n",
        "\n",
        "    # The color kwargs\n",
        "    \"brightness\": 0.25, \n",
        "    \"contrast\": 0.25, \n",
        "    \"saturation\": 0.25, \n",
        "    \"hue\": 0.1,\n",
        "    \n",
        "    # The crop kwargs\n",
        "    \"min_height\": processor.size[\"height\"],\n",
        "    \"min_width\" : processor.size[ \"width\"],\n",
        "    \n",
        "    # The geometric kwargs\n",
        "    \"rotate\": (-90, 90),\n",
        "    \"translate_percent\": 0.1\n",
        "}\n",
        "\n",
        "image_transform = albumentations.Compose([\n",
        "    albumentations.ColorJitter(\n",
        "        brightness=FLAGS[\"brightness\"], \n",
        "        contrast=FLAGS[\"contrast\"], \n",
        "        saturation=FLAGS[\"saturation\"], \n",
        "        hue=FLAGS[\"hue\"]\n",
        "    )\n",
        "])\n",
        "\n",
        "image_and_mask_transform = albumentations.Compose([\n",
        "    albumentations.Flip(p=FLAGS[\"proba\"]),\n",
        "    albumentations.Affine(\n",
        "        p=FLAGS[\"proba\"],\n",
        "        cval=FLAGS[\"fill_value\"],\n",
        "        cval_mask=FLAGS[\"mask_fill_value\"],\n",
        "        mode=FLAGS[\"border_mode\"],\n",
        "        rotate=FLAGS[\"rotate\"], \n",
        "        translate_percent=FLAGS[\"translate_percent\"],\n",
        "    ),\n",
        "    albumentations.PadIfNeeded(\n",
        "        border_mode=FLAGS[\"border_mode\"],\n",
        "        mask_value=FLAGS[\"mask_fill_value\"],\n",
        "        min_height=FLAGS[\"min_height\"], \n",
        "        min_width=FLAGS[\"min_width\"], \n",
        "        value=FLAGS[\"fill_value\"],\n",
        "    ),\n",
        "    albumentations.RandomCrop(\n",
        "        p=FLAGS[\"proba\"],\n",
        "        height=FLAGS[\"min_height\"], \n",
        "        width=FLAGS[\"min_width\"],\n",
        "    )\n",
        "])\n",
        "\n",
        "def train_transform(\n",
        "    batch: typing.Dict[str, typing.List[Any]]\n",
        ") -> transformers.BatchFeature:\n",
        "    images = [image.convert(\"RGB\") for image in batch[\"pixelmap\"]]\n",
        "    images = [np.array(image) for image in images]\n",
        "    images = [image_transform(image=image)[\"image\"] for image in images]\n",
        "\n",
        "    labels = [np.array(label).astype(np.uint8) for label in batch[\"labelmap\"]]\n",
        "\n",
        "    examples = [\n",
        "        image_and_mask_transform(image=image, mask=mask) \n",
        "        for image, mask in zip(images, labels)\n",
        "    ]\n",
        "\n",
        "    images = [example[\"image\"] for example in examples]\n",
        "    labels = [example[ \"mask\"] for example in examples]\n",
        "\n",
        "    encoding = processor(images, labels)\n",
        "    return encoding\n",
        "\n",
        "def  test_transform(\n",
        "    batch: typing.Dict[str, typing.List[Any]]\n",
        ") -> transformers.BatchFeature:\n",
        "    images = [image.convert(\"RGB\") for image in batch[\"pixelmap\"]]\n",
        "    labels = [label for label in batch[\"labelmap\"]]\n",
        "\n",
        "    encoding = processor(images, labels)\n",
        "    return encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u3EHJJcZ7seI"
      },
      "outputs": [],
      "source": [
        "train_dataset.set_transform(train_transform)\n",
        "test_dataset.set_transform(test_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi8OMuCCNgXB"
      },
      "source": [
        "## 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "kwargs = {\n",
        "    \"master-addr\": \"localhost\",\n",
        "    \"master-port\": \"9994\",  # modify if RuntimeError: Address already in use\n",
        "    \"rank\": \"0\",\n",
        "    \"local-rank\": \"0\",\n",
        "    \"world-size\": \"1\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "for key, val in kwargs.items():\n",
        "    key = key.replace(\"-\", \"_\")\n",
        "    key = key.upper()\n",
        "\n",
        "    os.environ[key] = val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# devices = [\"0\", \"1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def _setup_env_variables() -> None:\n",
        "#     kwargs = {\n",
        "#         \"cuda-visible-devices\": \",\".join(devices),\n",
        "#         \"tokenizers-parallelism\": \"false\"\n",
        "#     }\n",
        "\n",
        "#     for key, val in kwargs.items():\n",
        "#         key = key.replace(\"-\", \"_\")\n",
        "#         key = key.upper()\n",
        "\n",
        "#         os.environ[key] = val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# _setup_env_variables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QAuL5fYuLQe9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "# from accelerate import notebook_launcher\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "\n",
        "import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QCG0Ndk-7KTG"
      },
      "outputs": [],
      "source": [
        "datasets.logging.set_verbosity_error()\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = metrics.DIBCO()\n",
        "logger = transformers.logging.get_logger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(outputs: transformers.EvalPrediction) -> typing.Dict[str, float]:\n",
        "    with torch.no_grad():\n",
        "        logits, references = outputs\n",
        "               \n",
        "        print(logits.min(), logits.max(), logits.dtype, logits.shape, references.min(), references.max(), references.dtype, references.shape)\n",
        "\n",
        "        logits = torch.from_numpy(logits)\n",
        "        logits = torch.float32(logits)\n",
        "\n",
        "        # It upscales the logits to the size of the label\n",
        "        preds = F.interpolate(\n",
        "            logits,\n",
        "            size=references.shape[-2:],\n",
        "            mode=\"bilinear\",\n",
        "            align_corners=False,\n",
        "        ).argmax(dim=1)\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        # references = references.astype(np.float(32))\n",
        "        # preds = preds.astype(np.float(32))\n",
        "\n",
        "        batch_metrics = metric(references, preds)\n",
        "        return batch_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_segformer() -> None:\n",
        "    FLAGS = {\n",
        "        \"accumulation_steps\": 16,\n",
        "        \"base_model_name\": base_model_name,\n",
        "        \"batch_size\": 1,\n",
        "        \"model_name\": \"binarization-segformer-b3\"\n",
        "    }\n",
        "    # FLAGS = {\n",
        "    #     \"accumulation_steps\": 4 / len(devices),\n",
        "    #     \"base_model_name\": base_model_name,\n",
        "    #     \"batch_size\": 1,\n",
        "    #     \"fp16\": torch.cuda.is_available(),\n",
        "    #     \"learning_rate\": 5e-5,\n",
        "    #     \"metric\": \"dibco\",\n",
        "    #     \"model_name\": \"binarization-segformer-b3\",\n",
        "    #     \"num_epochs\": 50,\n",
        "    #     \"optimizer\": \"adamw_torch\",\n",
        "    #     \"scheduler_type\": \"cosine\"\n",
        "    # }\n",
        "\n",
        "    model_kwargs = {\n",
        "        \"id2label\": id2label, \n",
        "        \"label2id\": label2id,\n",
        "        \"ignore_mismatched_sizes\": True,\n",
        "    }\n",
        "\n",
        "    model = transformers.SegformerForSemanticSegmentation.from_pretrained(FLAGS[\"base_model_name\"], **model_kwargs)\n",
        "\n",
        "    training_args = transformers.TrainingArguments(\n",
        "        # auto_find_batch_size=True,\n",
        "        deepspeed=\"ds-config-zero2.json\",\n",
        "        # eval_accumulation_steps=FLAGS[\"accumulation_steps\"],\n",
        "        eval_steps=10,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        full_determinism=False,\n",
        "        gradient_accumulation_steps=FLAGS[\"accumulation_steps\"],\n",
        "        # gradient_checkpointing=True,\n",
        "        hub_model_id=FLAGS[\"model_name\"],\n",
        "        hub_strategy=\"end\",\n",
        "        # learning_rate=FLAGS[\"learning_rate\"],\n",
        "        load_best_model_at_end=True,\n",
        "        logging_steps=10,\n",
        "        # lr_scheduler_type=FLAGS[\"scheduler_type\"],\n",
        "        num_train_epochs=50,\n",
        "        # optim=FLAGS[\"optimizer\"],\n",
        "        output_dir=FLAGS[\"model_name\"],\n",
        "        per_device_eval_batch_size=FLAGS[\"batch_size\"],\n",
        "        per_device_train_batch_size=FLAGS[\"batch_size\"],\n",
        "        push_to_hub=True,\n",
        "        remove_unused_columns=False,  # https://discuss.huggingface.co/t/divide-by-zero-error-when-following-ch7-tutorial/18393/6\n",
        "        report_to=\"tensorboard\",\n",
        "        save_steps=10,\n",
        "        save_strategy=\"steps\",\n",
        "        save_total_limit=3,\n",
        "        seed=10,\n",
        "        # warmup_steps=50,\n",
        "    )\n",
        "    \n",
        "    callbacks = [\n",
        "        transformers.EarlyStoppingCallback(early_stopping_patience=5)\n",
        "    ]\n",
        "\n",
        "    trainer = transformers.Trainer(\n",
        "        args=training_args,\n",
        "        callbacks=callbacks,\n",
        "        compute_metrics=compute_metrics,\n",
        "        eval_dataset=test_dataset,\n",
        "        model=model,    \n",
        "        train_dataset=train_dataset,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        checkpoint = get_last_checkpoint(FLAGS[\"model_name\"])\n",
        "    except FileNotFoundError:\n",
        "        logger.debug(\"No checkpoint\")\n",
        "        checkpoint = None\n",
        "\n",
        "    resume_from_checkpoint = checkpoint is not None\n",
        "\n",
        "    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
        "\n",
        "    trainer.save_model()  # It saves the tokenizer too for easy upload\n",
        "    trainer.save_state()   \n",
        "\n",
        "    kwargs = {\n",
        "        \"finetuned_from\": FLAGS[\"base_model_name\"],\n",
        "        \"tags\": [\n",
        "            \"document-image-binarization\"\n",
        "            \"image-segmentation\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    processor.push_to_hub(FLAGS[\"model_name\"])\n",
        "    trainer.push_to_hub(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-07-10 12:10:07,948] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2023-07-10 12:10:14,066] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
            "[2023-07-10 12:10:14,066] [INFO] [comm.py:594:init_distributed] cdb=None\n",
            "[2023-07-10 12:10:14,067] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fminutoli/Personal/binarization-segformer/binarization-segformer-b3 is already a clone of https://huggingface.co/DiTo97/binarization-segformer-b3. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/home/fminutoli/Personal/binarization-segformer/binarization-segformer-b3 is already a clone of https://huggingface.co/DiTo97/binarization-segformer-b3. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination\n",
            "Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using /home/fminutoli/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /home/fminutoli/.cache/torch_extensions/py37_cu117/cpu_adam/build.ninja...\n",
            "Building extension module cpu_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ninja: no work to do.\n",
            "Time to load cpu_adam op: 2.6278932094573975 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading extension module cpu_adam...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank: 0 partition count [1] and sizes[(47224002, False)] \n",
            "{'loss': 0.0, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
            "-1.7705 0.945 float16 (52, 2, 256, 256) 0 1 int64 (52, 1024, 1024)\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'torch.dtype' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_12853/3415756088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_segformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_12853/2146109699.py\u001b[0m in \u001b[0;36mtrain_segformer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It saves the tokenizer too for easy upload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/binarization-segformer/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1638\u001b[0m         )\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/binarization-segformer/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/binarization-segformer/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2234\u001b[0m                     )\n\u001b[1;32m   2235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/binarization-segformer/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m         )\n\u001b[1;32m   2941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/binarization-segformer/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3218\u001b[0m                 )\n\u001b[1;32m   3219\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3220\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3221\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3222\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_12853/75666132.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# It upscales the logits to the size of the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'torch.dtype' object is not callable"
          ]
        }
      ],
      "source": [
        "train_segformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8foaMGZlLEzz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # metric = evaluate.load(FLAGS[\"metric\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#         batch_size, height, width = logits.shape\n",
        "\n",
        "#         # npixel = height*width\n",
        "\n",
        "#         # fmeasures = []\n",
        "#         # pfmeasures = []\n",
        "#         # psnrs = []\n",
        "#         # drds = []\n",
        "\n",
        "#         # for idx in range(batch_size):\n",
        "#         #     im = predictions[idx]\n",
        "#         #     im_gt = labels[idx]\n",
        "\n",
        "#         #     fmeasure = Fmeasure(im, im_gt)\n",
        "#         #     psnr = Psnr(im, im_gt)\n",
        "#         #     pfmeasure = Pfmeasure(im, im_gt)\n",
        "#         #     drd = DRD(im, im_gt)\n",
        "\n",
        "#         #     fmeasures.append(fmeasure)\n",
        "#         #     pfmeasures.append(pfmeasure)\n",
        "#         #     psnrs.append(psnr)\n",
        "#         #     drds.append(drd)\n",
        "\n",
        "#         # batch_fmeasure = np.mean(fmeasures)\n",
        "#         # batch_pfmeasure = np.mean(pfmeasures)\n",
        "#         # batch_psnr = np.mean(psnrs)\n",
        "#         # batch_drd = np.mean(drds)\n",
        "\n",
        "#         # metrics = {\n",
        "#         #     \"fmeasure\": batch_fmeasure,\n",
        "#         #     \"pfmeasure\": batch_pfmeasure,\n",
        "#         #     \"psnr\": batch_psnr,\n",
        "#         #     \"drd\": batch_drd\n",
        "#         # }\n",
        "\n",
        "#         # return metrics\n",
        "\n",
        "#         # # FIXME: For more information, see\n",
        "#         # # https://github.com/huggingface/evaluate/pull/328#issuecomment-1286866576\n",
        "#         # metrics = metric._compute(\n",
        "#         #         predictions=predictions,\n",
        "#         #         references=labels,\n",
        "#         #         num_labels=num_labels,\n",
        "#         #         ignore_index=0,  # The background info is ignored\n",
        "#         #         reduce_labels=processor.do_reduce_labels,\n",
        "#         #     )\n",
        "        \n",
        "#         # # It adds per-category metrics as separate key-val pairs\n",
        "#         # per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
        "#         # per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
        "\n",
        "#         # metrics.update({f\"accuracy_{id2label[key]}\": val for key, val in enumerate(per_category_accuracy)})\n",
        "#         # metrics.update({f\"iou_{id2label[key]}\": val for key, val in enumerate(per_category_iou)})\n",
        "        \n",
        "#         # return metrics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n",
        "# # decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
        "\n",
        "# # c = [\n",
        "# #     {\n",
        "# #         \"params\": [\n",
        "# #              param for name, param in model.named_parameters() \n",
        "# #              if name in decay_parameters\n",
        "# #         ],\n",
        "# #         \"weight_decay\": training_args.weight_decay,\n",
        "# #     },\n",
        "# #     {\n",
        "# #         \"params\": [\n",
        "# #              param for name, param in model.named_parameters() \n",
        "# #              if name in decay_parameters\n",
        "# #         ],\n",
        "# #         \"weight_decay\": 0.0,\n",
        "# #     },\n",
        "# # ]\n",
        "\n",
        "# # optim_kwargs = {\n",
        "# #     \"betas\": (training_args.adam_beta1, training_args.adam_beta2),\n",
        "# #     \"eps\": training_args.adam_epsilon,\n",
        "# # }\n",
        "# # optim_kwargs[\"lr\"] = training_args.learning_rate\n",
        "\n",
        "# # adam_8bit_optim = bitsandbytes.optim.Adam8bit(\n",
        "# #     optim_kwargs,\n",
        "# #     betas=(training_args.adam_beta1, training_args.adam_beta2),\n",
        "# #     eps=training_args.adam_epsilon,\n",
        "# #     lr=training_args.learning_rate,\n",
        "# # )\n",
        "\n",
        "# callbacks = [\n",
        "#     transformers.EarlyStoppingCallback(early_stopping_patience=5)\n",
        "# ]\n",
        "\n",
        "# trainer = transformers.Trainer(\n",
        "#     args=training_args,\n",
        "#     callbacks=callbacks,\n",
        "#     compute_metrics=compute_metrics,\n",
        "#     eval_dataset=test_dataset,\n",
        "#     model=model,    \n",
        "#     train_dataset=train_dataset,\n",
        "#     # optimizers=(adam_8bit_optim, None)\n",
        "# )\n",
        "\n",
        "# try:\n",
        "#     checkpoint = get_last_checkpoint(FLAGS[\"model_name\"])\n",
        "# except FileNotFoundError:\n",
        "#     logger.debug(\"No checkpoint\")\n",
        "#     checkpoint = None\n",
        "\n",
        "# resume_from_checkpoint = checkpoint is not None\n",
        "\n",
        "# trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
        "\n",
        "# trainer.save_model()  # It saves the tokenizer too for easy upload\n",
        "# trainer.save_state()   \n",
        "\n",
        "# kwargs = {\n",
        "#     \"finetuned_from\": FLAGS[\"base_model_name\"],\n",
        "#     \"tags\": [\n",
        "#         \"document-image-binarization\"\n",
        "#         \"image-segmentation\"\n",
        "#     ]\n",
        "# }\n",
        "\n",
        "# processor.push_to_hub(FLAGS[\"model_name\"])\n",
        "# trainer.push_to_hub(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2RW-caNNh4T"
      },
      "source": [
        "## 4. Inference\n",
        "\n",
        "For a complete example, see T. Cornille's official Segformer [blog post](https://huggingface.co/blog/fine-tune-segformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTgfBrTw25u1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
